{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning progress: Evaluación del BERT a lo largo de las etapas del finetuning\n",
    "\n",
    "Lo vamos a hacer primero con un conjunto de prueba:\n",
    "* Abstracts de los que se tomó la muestra: [abstracts.csv](../../pubmed-queries/abstracts/abstracts.csv)\n",
    "* Muestra fenotipos/etiquetas: [index-phenotypes.csv](../../pubmed-queries/abstracts/index-phenotypes.csv)\n",
    "* Fenotipos test: [phenotypes-22-12-15.csv](../pubmed-queries/results/phenotypes-22-12-15.csv) = nodos hoja HPO:PhenotypicAbnormality\n",
    "\n",
    "Pasos a seguir:\n",
    "1. Cargar todos los datos:\n",
    "  * BERT de partida.\n",
    "  * Ontología.\n",
    "  * Datos crudos de entrenamiento (abstracts+fenotipos).\n",
    "2. Preparar el entrenamiento:\n",
    "  * Datos procesados de train (dataloaders)\n",
    "  * Función de pérdida: BatchAllTripletLoss\n",
    "  * Función de evaluación:\n",
    "    * a) EmbeddingSimilarityEvaluator\n",
    "      * Preparar pares de fenotipos (train/test?)\n",
    "      * Calcular gold scores\n",
    "    * b) Implementarla (SentenceEvaluator) con la funcionalidad:\n",
    "      * Calcular MSE y correlación Train/Test.\n",
    "      * Escribir datos en un csv.\n",
    "      * Devolver la correlación de Test.\n",
    "3. Fit: probar en el servidor y guardar los resultados.\n",
    "4. Out: mostrar e interpretar los resultados.\n",
    "  * Gráfica MSE / etapa (train/test)\n",
    "  * Gráfica correlación / etapa (train/test)\n",
    "\n",
    "## 1. Cargar todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from cmath import nan\n",
    "import sentence_transformers\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Cargar todos los datos (crudos)\n",
    "from pyhpo import Ontology\n",
    "import os\n",
    "\n",
    "SRCPATH = '../..'\n",
    "SEED = 42\n",
    "\n",
    "# 1.1 BERT de partida\n",
    "\n",
    "PRITAMDEKAMODEL = 'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb'\n",
    "bertmodel = SentenceTransformer(PRITAMDEKAMODEL)\n",
    "model = bertmodel\n",
    "\n",
    "# 1.2 Ontología\n",
    "\n",
    "onto = Ontology(SRCPATH+ '/pubmed-queries/hpo-22-12-15-data')\n",
    "\n",
    "# 1.3 Datos crudos de entrenamiento\n",
    "\n",
    "PATH_DATA = SRCPATH + '/pubmed-queries/abstracts'\n",
    "PATH_DATA_CSV = PATH_DATA + '/abstracts.csv'\n",
    "PATH_DATA_FENOTIPOS = SRCPATH + '/pubmed-queries/results/phenotypes-22-12-15.csv'\n",
    "PATH_INDEX_FENOTIPOS = PATH_DATA + '/index-phenotypes.csv'\n",
    "\n",
    "# abstracts\n",
    "dfPapers = pd.read_csv(PATH_DATA_CSV, sep='\\t', low_memory=False, na_values=['', nan])\n",
    "# fenotipos test\n",
    "dfPhenotypes = pd.read_csv(PATH_DATA_FENOTIPOS, sep=';', low_memory=False, na_values=['', nan])\n",
    "# fenotipos train\n",
    "dfIndex = pd.read_csv(PATH_INDEX_FENOTIPOS, sep='\\t', low_memory=False, na_values=['', nan])\n",
    "\n",
    "# Guardar en directorio manejable\n",
    "PATH_TRAINDATA = SRCPATH + '/traindata'\n",
    "\n",
    "# crear directorios si no existen\n",
    "for dir in [PATH_TRAINDATA, PATH_TRAINDATA + '/abstracts',\n",
    "            PATH_TRAINDATA + '/phenotypes', PATH_TRAINDATA + '/onto']:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "dfPapers.to_csv(PATH_TRAINDATA + '/abstracts/abstracts.csv', sep='\\t', index=False)\n",
    "dfPhenotypes.to_csv(PATH_TRAINDATA + '/phenotypes/phenotypes.csv', sep=';', index=False)\n",
    "dfIndex.to_csv(PATH_TRAINDATA + '/phenotypes/index.csv', sep='\\t', index=False)\n",
    "\n",
    "# copiar ontology al directorio tambien\n",
    "os.system('cp -r ' + SRCPATH + '/pubmed-queries/hpo-22-12-15-data ' + PATH_TRAINDATA + '/onto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparar el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na's: 1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/domingo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/domingo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean abstracts in:  ../../traindata/abstracts/abstracts-clean.csv\n",
      "Total abstracts:  23226\n",
      "Number of phenotype tags: 100\n"
     ]
    }
   ],
   "source": [
    "# Procesar los datos de train/loss/test\n",
    "\n",
    "# 2.1. Clean abstracts\n",
    "\n",
    "# Tratar NA's en la columna abstracts -> cambiar por el título\n",
    "def getPhenDesc(phenotypeName):\n",
    "    hpoNode = onto.get_hpo_object(phenotypeName) \n",
    "    description = hpoNode.definition if hpoNode.definition else '\"\"'\n",
    "    return description\n",
    "\n",
    "print('Na\\'s:', dfPapers['abstract'].isna().sum())\n",
    "dfPapers['abstract'] = dfPapers['abstract'].fillna(dfPapers['title'])\n",
    "\n",
    "# Función clean abstract\n",
    "\n",
    "# Download the stopwords from NLTK\n",
    "PATH_NTLK = SRCPATH + '/traindata/nltk'\n",
    "if not os.path.exists(PATH_NTLK):\n",
    "    os.makedirs(PATH_NTLK)\n",
    "\n",
    "os.environ['NLTK_DATA'] = PATH_NTLK\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "cached_stopwords = stopwords.words('english')\n",
    "def clean_abstract(abstract):\n",
    "    if isinstance(abstract, float) and np.isnan(abstract):\n",
    "        return ''\n",
    "    # Convert the text to lowercase\n",
    "    abstract = abstract.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    abstract = abstract.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(abstract)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if not word in cached_stopwords]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    abstract = ' '.join(tokens)\n",
    "\n",
    "    return abstract\n",
    "\n",
    "# Save clean abstracts csv\n",
    "\n",
    "dfPapers['clean_abstract'] = dfPapers['abstract'].apply(clean_abstract)\n",
    "dfPapers.drop(columns=['abstract'], inplace=True)\n",
    "dfPapers.to_csv(PATH_TRAINDATA + '/abstracts/abstracts-clean.csv', sep='\\t', index=False)\n",
    "\n",
    "print('Clean abstracts in: ', PATH_TRAINDATA + '/abstracts/abstracts-clean.csv')\n",
    "print('Total abstracts: ', len(dfPapers))\n",
    "\n",
    "# 2.2 Tags = phenotypes (train)\n",
    "\n",
    "tags = dfIndex['phenotypeName']\n",
    "numlabels = len(tags)\n",
    "print('Number of phenotype tags:', numlabels)\n",
    "mapping = {tag: i for i, tag in enumerate(tags)}\n",
    "\n",
    "def getLabelNumber(phenotypeName):\n",
    "    return mapping[phenotypeName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Profiling\n",
    "Tomamos solo una muestra del 5% de los abstracts totales para realizar las pruebas más rápido. Cuando funcionen las pruebas se cambia para la versión oficial del experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 232\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, losses, evaluation, InputExample\n",
    "\n",
    "PROFILING = True\n",
    "SAMPLEPERCENT = 0.01 if PROFILING else 1.0\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "dTrain = dfPapers.sample(frac=SAMPLEPERCENT, random_state=SEED)\n",
    "numexamples = len(dTrain)\n",
    "print('Number of train examples:', numexamples)\n",
    "dTrain.to_csv(PATH_TRAINDATA + '/abstracts/abstracts-train.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test pairs samples: 500\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos de entrenamiento\n",
    "\n",
    "# pares (abstract,fenotipo)\n",
    "abstractsTrain = [InputExample(texts=[clean_abstract(x)], label=mapping[y]) for x, y in zip(dTrain['clean_abstract'], dTrain['phenotypeName'])]\n",
    "train_dataloader = DataLoader(abstractsTrain, shuffle=True, batch_size=16)\n",
    "\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Ejemplos de evaluación (train)\n",
    "\n",
    "def onto_distance(name1, name2):\n",
    "    phen1 = onto.get_hpo_object(name1)\n",
    "    phen2 = onto.get_hpo_object(name2)\n",
    "    dist = max(1-phen1.similarity_score(phen2, method='lin'),0)\n",
    "    return dist\n",
    "\n",
    "# Son pares de fenotipos (con su gold score si es necesario)\n",
    "dmp = pd.DataFrame(dfIndex, columns=['phenotypeName'])\n",
    "index_pairs = combinations(range(0,len(dmp)), 2)\n",
    "\n",
    "lpairs = list(combinations(dmp['phenotypeName'], 2))\n",
    "ltrain1, ltrain2 = zip(*lpairs) # 2 listas diferentes para pasar como parámetro al evaluator\n",
    "\n",
    "goldTrain = [onto_distance(pair[0], pair[1]) for pair in lpairs]\n",
    "\n",
    "# Ejemplos de evaluación (test)\n",
    "\n",
    "import random\n",
    "\n",
    "def random_combination(iterable, r):\n",
    "    \"Random selection from itertools.combinations(iterable, r)\"\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    indices = sorted(random.sample(range(n), r))\n",
    "    return tuple(pool[i] for i in indices)\n",
    "\n",
    "# Obtén una lista de todos los valores únicos en la columna 'phenotypeName'\n",
    "\n",
    "num_samples = 500  # Number of combinations to sample\n",
    "print('Number of test pairs samples:', num_samples)\n",
    "\n",
    "# Usa random_combination para obtener una muestra aleatoria de 2000 pares\n",
    "sample_pairs = [random_combination(dfPhenotypes['Phenotype'], 2) for _ in range(num_samples)]\n",
    "ltest1, ltest2 = zip(*sample_pairs)\n",
    "\n",
    "goldTest = [onto_distance(pair[0], pair[1]) for pair in sample_pairs]\n",
    "\n",
    "# Guardar los pares de evaluación\n",
    "\n",
    "dfVal = pd.DataFrame({'phenotype1': ltrain1, 'phenotype2': ltrain2, 'lin': goldTrain})\n",
    "dfTest = pd.DataFrame({'phenotype1': ltest1, 'phenotype2': ltest2, 'lin': goldTest})\n",
    "\n",
    "if not os.path.exists(PATH_TRAINDATA + '/evaluation'):\n",
    "    os.makedirs(PATH_TRAINDATA + '/evaluation')\n",
    "\n",
    "dfVal.to_csv(PATH_TRAINDATA + '/evaluation/pairs-val.csv', sep='\\t', index=False)\n",
    "dfTest.to_csv(PATH_TRAINDATA + '/evaluation/pairs-test.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Funciones de pérdida y evaluación\n",
    "* Primero probaremos la opción a) con la función predefinida EmbeddingSimilarityEvaluator para los datos de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: BatchAllTripletLoss(margin=0.3743)\n",
      "Evaluator: EmbeddingSimilarityEvaluator(cosine_similarity)\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "\n",
    "MARGIN = 0.3743\n",
    "print(f'Loss Function: BatchAllTripletLoss(margin={MARGIN})')\n",
    "train_loss = losses.BatchAllTripletLoss(model=model, distance_metric=losses.BatchHardTripletLossDistanceFunction.cosine_distance, margin=MARGIN)\n",
    "\n",
    "# Evaluator\n",
    "\n",
    "# a)\n",
    "\n",
    "evaluatorTrain=sentence_transformers.evaluation.EmbeddingSimilarityEvaluator(ltrain1, ltrain2, goldTrain)\n",
    "evaluatorTest=sentence_transformers.evaluation.EmbeddingSimilarityEvaluator(ltest1, ltest2, goldTest)\n",
    "combined_evaluator = evaluation.SequentialEvaluator([evaluatorTrain, evaluatorTest])\n",
    "print('Evaluator: EmbeddingSimilarityEvaluator(cosine_similarity)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit parameters: num_epochs=5, evaluation_steps=14,warmup_steps=3\n",
      "Fitting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05441f5b1d264777b20c98746b112e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a1c85782f84d26ba2ea0e4cb68269e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown main_similarity value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFit parameters: num_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation_steps=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mev_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,warmup_steps=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39m(num_examples\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m16\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m fmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#evaluation_steps=(num_examples//16)//num_epochs//2,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mev_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSRCPATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/output/fine-tuned-bio-bert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#save_best_model=True,\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./checkpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_save_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mev_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_save_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sda1/programas-linux/miniconda3/envs/bert/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:882\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    879\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluation_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m training_steps \u001b[38;5;241m%\u001b[39m evaluation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 882\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_during_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss_model \u001b[38;5;129;01min\u001b[39;00m loss_models:\n\u001b[1;32m    887\u001b[0m         loss_model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/mnt/sda1/programas-linux/miniconda3/envs/bert/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:928\u001b[0m, in \u001b[0;36mSentenceTransformer._eval_during_training\u001b[0;34m(self, evaluator, output_path, save_best_model, epoch, steps, callback)\u001b[0m\n\u001b[1;32m    925\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(eval_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 928\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m         callback(score, epoch, steps)\n",
      "File \u001b[0;32m/mnt/sda1/programas-linux/miniconda3/envs/bert/lib/python3.11/site-packages/sentence_transformers/evaluation/SequentialEvaluator.py:20\u001b[0m, in \u001b[0;36mSequentialEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     18\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluators:\n\u001b[0;32m---> 20\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain_score_function(scores)\n",
      "File \u001b[0;32m/mnt/sda1/programas-linux/miniconda3/envs/bert/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:183\u001b[0m, in \u001b[0;36mEmbeddingSimilarityEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(eval_spearman_cosine, eval_spearman_manhattan, eval_spearman_euclidean, eval_spearman_dot)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown main_similarity value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown main_similarity value"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_examples = len(dTrain)\n",
    "ev_steps = num_examples//16\n",
    "\n",
    "if not os.path.exists(SRCPATH + '/output'):\n",
    "    os.makedirs(SRCPATH + '/output')\n",
    "\n",
    "print(f'Fit parameters: num_epochs={num_epochs},',\n",
    "      f'evaluation_steps={ev_steps},warmup_steps={int(0.25*(num_examples//16))}')\n",
    "print(\"Fitting...\")\n",
    "fmodel = model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=combined_evaluator,\n",
    "    epochs=num_epochs,\n",
    "    #evaluation_steps=(num_examples//16)//num_epochs//2,\n",
    "    evaluation_steps=ev_steps,\n",
    "    warmup_steps=int(0.25*(num_examples//16)),\n",
    "    output_path=SRCPATH+'/output/fine-tuned-bio-bert',\n",
    "    #save_best_model=True,\n",
    "    checkpoint_path='./checkpoint',\n",
    "    checkpoint_save_steps=ev_steps,\n",
    "    checkpoint_save_total_limit=num_epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
