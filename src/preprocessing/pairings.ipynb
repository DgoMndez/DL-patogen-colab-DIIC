{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestreo de pares de abstracts\n",
    "Vamos a construir un csv que tenga pares de abstracts, sus fenotipos asociados y su similitud lin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/domingo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/domingo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import global variables from project_config.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from IPython.core.getipython import get_ipython\n",
    "\n",
    "# Absolute path of the current notebook\n",
    "notebook_path = os.path.realpath(os.path.join(os.getcwd(), get_ipython().starting_dir))\n",
    "# Add module to system path\n",
    "src_path = os.path.dirname(notebook_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import project_config.project_config\n",
    "from project_config.project_config import *\n",
    "from util.clean_abstracts import clean_abstract\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from cmath import nan\n",
    "from util.clean_abstracts import countPapers, getIndex\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load abstracts and index data\n",
    "\n",
    "NAME_ABSTRACTS = 'abstracts-31-05-train'\n",
    "\n",
    "NAME_INDEX = \"index-31-05-train\"\n",
    "NAME_PHEN = \"phenotypes_nz_05-05_10\"\n",
    "\n",
    "PATH_ABSTRACTS_CSV = PATH_ABSTRACTS + '/' + NAME_ABSTRACTS + \".csv\"\n",
    "PATH_INDEX_CSV = PATH_PHENOTYPES +'/'+ NAME_INDEX + \".csv\"\n",
    "PATH_DATA_FENOTIPOS = PATH_PHENOTYPES + '/' + NAME_PHEN + \".csv\"\n",
    "\n",
    "dfPhen = pd.read_csv(PATH_DATA_FENOTIPOS, sep='\\t', low_memory=False, na_values=['', nan])\n",
    "dfIndex = pd.read_csv(PATH_INDEX_CSV, sep='\\t', low_memory=False, na_values=['', nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAbstracts = pd.read_csv(PATH_ABSTRACTS_CSV, sep='\\t', low_memory=False, na_values=['', nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 802664 entries, 0 to 802663\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   paperId         802664 non-null  int64 \n",
      " 1   phenotypeId     802664 non-null  object\n",
      " 2   phenotypeName   802664 non-null  object\n",
      " 3   title           802664 non-null  object\n",
      " 4   clean_abstract  802664 non-null  object\n",
      " 5   length          802664 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 36.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4070 entries, 0 to 4069\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   phenotypeId    4070 non-null   object\n",
      " 1   numberPapers   4070 non-null   int64 \n",
      " 2   phenotypeName  4070 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 95.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6107 entries, 0 to 6106\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       6107 non-null   object \n",
      " 1   name     6107 non-null   object \n",
      " 2   def      5102 non-null   object \n",
      " 3   depth    6107 non-null   int64  \n",
      " 4   isLeaf   6107 non-null   bool   \n",
      " 5   ic       6107 non-null   float64\n",
      " 6   ic_gene  6107 non-null   float64\n",
      " 7   ic_omim  6107 non-null   float64\n",
      "dtypes: bool(1), float64(3), int64(1), object(3)\n",
      "memory usage: 340.1+ KB\n",
      "Number of papers: 802664, Number of phen: 4070\n"
     ]
    }
   ],
   "source": [
    "dfPapers = dfAbstracts\n",
    "dfPapers.info()\n",
    "dfIndex.info()\n",
    "dfPhen.info()\n",
    "\n",
    "m = dfIndex.shape[0]\n",
    "n = dfPapers.shape[0]\n",
    "print(f\"Number of papers: {n}, Number of phen: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "s = datetime.today().strftime('%d-%m')\n",
    "\n",
    "import math\n",
    "import random\n",
    "from itertools import combinations\n",
    "import bisect\n",
    "\n",
    "# get all combinations of test phenotypes\n",
    "\n",
    "testNames = testPhen['name'].tolist()\n",
    "pairs = list(combinations(testNames, 2))\n",
    "\n",
    "from pyhpo import Ontology\n",
    "\n",
    "def random_combinations(iterable, k, size):\n",
    "    \"Sample n=size combinations of k elements from iterable without replacement.\"\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    m = (math.comb(n,k))\n",
    "    codes = random.sample(range(m), size)\n",
    "    l = list()\n",
    "    # Given j=code, get the j-th combination\n",
    "    for code in codes:\n",
    "        indices = np.array([], dtype=int)\n",
    "        j = code\n",
    "        for i in range(k):\n",
    "            q, r = divmod(j, n-i)\n",
    "            index = bisect.bisect_right(indices, r)\n",
    "            r = r + index\n",
    "            indices = np.insert(indices, index, r)\n",
    "            j = q\n",
    "        l.append(pool[i] for i in list(indices)) \n",
    "    return l\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
